# SPARK_FUNDAMENTAL

#P1
##EASY
###BC

1. Which is a component on top of Spark Core.?

A. Spark Streaming
B. Spark SQL
C. RDDs
D. None of the above

Answer: B

#P1
##EASY
###BC

2. Which is a distributed graph processing framework on top of Spark.

A. MLlib
B. Spark Streaming
C. GraphX
D. None of the above

Answer: C

#P1
##EASY
###TF

3.Spark enables Apache Hive users to run their unmodified queries much faster.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

4. Spark is a popular data warehouse solution running on top of Hadoop?

A. True 
B. False 

Answer: B

#P1
##EASY
###TF

5. Spark interoperates only with Hadoop.

A. True 
B. False 

Answer: B

#P1
##EASY
###BC

6. ________ can be used to launch Spark jobs inside MapReduce?

A. SIM    
B. SIMR
C. SIR
D. RIS

Answer: B

#P1
##EASY
###BC

7. We want to create a DataFrame based on HR data that will provide the dataset parsed differently for managers, employees, and HR personnel. Which method will you use to create the DataFrame?

A. Create DataFrame by programmatically constructing the schema
B. Create the DataFrame by inferring the schema by reflection
C. Both A and B
D. None 

Answer: A

#P1
##EASY
###BC

8. Which of the following is true of running a Spark application on Hadoop YARN? 

A. In Hadoop YARN mode, the RDDs and variables are always in the same memory space
B. Running in Hadoop YARN has the advantage of having multiple users running the Spark interactive shell
C. There are two deploy modes that can be used to launch Spark applications on YARN - client mode and cluster mode
D. Irrespective of the mode, the driver is launched in the client process that submitted the job

Answer: C

#P1
##EASY
###BC

9. A DataFrame can be created from an existing RDD. You would create the DataFrame from the existing RDD by inferring the schema using case classes in which case?

A. If your dataset has more than 22 fields
B. If all your users are going to need the dataset parsed in the same way
C. If you have two sets of users who will need the text dataset parsed differently
D. None 

Answer: B

#P1
##EASY
###BC

10. Spark was initially started by ____________ at UC Berkeley AMPLab in 2009.

A. Mahek Zaharia
B. Matei Zaharia
C. Doug Cutting
D. Stonebraker

Answer: A

#P1
##EASY
###BC

11.______ can be used to launch Spark jobs inside MapReduce?

A. SIM
B. SIMR
C. SIR
D. RIS

Answer: B

#P1
##EASY
###BC

12. Spark includes a collection over ________ operators for transforming data and familiar data frame APIs for manipulating semi-structured data.

A. 50
B. 60
C. 70
D. 80

Answer: D

#P1
##EASY
###BC

13. Given a DataFrame df that includes a number of columns among which a column named quantity and a column named price, complete the code below such that it will create a DataFrame including all the original columns and a new column revenue defined as quantity*price:

A. df.withColumnRenamed(“revenue”, expr(“quantity*price”))
B. df.withColumn(revenue, expr(“quantity*price”))
C. df.withColumn(“revenue”, expr(“quantity*price”))
D. df.withColumn(expr(“quantity*price”), “revenue”)

Answer: C

#P1
##EASY
###BC

14. What is action in Spark RDD?

A. The ways to send result from executors to the driver
B. Takes RDD as input and produces one or more RDD as output.
C. Creates one or many new RDDs
D. All of the above

Answer: A

#P1
##EASY
###TF

15.Hadoop and Spark are data processing platforms.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

16. Hadoop and Spark are cluster computing environments.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

17. Hadoop and Spark use open source APIs to link between different tools.

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

18. How much faster can spark run batch processing when processed in memory than mapreduce?

A. 10 times faster 
B. 20 times faster
C. 100 times faster 
D. 200 times faster 

Answer: B

#P1
##EASY
###BC

19. ______ provide the Spark Core’s fast scheduling capability to perform streaming analytics.

A. RDD 
B. Graphx 
C. Spark Streaming 
D. Spark R 

Answer: C

#P1
##EASY
###BC

20. _______ provide the Spark Core’s fast scheduling capability to perform streaming analytics.

A. DAG execution engine and in-memory computation
B. Support for different language APIs like Java, Python and R
C. RDDs are immutable and fault-tolerant
D. None of the above 

Answer: A

#P1
##EASY
###TF

21. RDD in Apache Spark is an immutable collection of objects.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

22. RDD is programming paradigm.

A. True 
B. False 

Answer: B

#P1
##EASY
###TF

23. RDD is database.

A. True 
B. false 

Answer: B
#P1
##EASY
###BC

24. _____ is not a function of Spark Context in Apache Spark?

A. Entry point to Spark SQL 
B. To Access various services 
C. To Set the configuration 
D. To get the current status of Spark Application 

Answer: A

#P1
##EASY
###BC

25. What are the features of Spark RDD?

A. In - memory computation 
B. Lazy evaluations 
C. Fault Tolerance 
D. All of the above 

Answer: D

#P1
##EASY
###BC

26. ______ many Spark Context can be active per JVM?

A. More than one 
B. Only one 
C. Not specific 
D. None of the above 

Answer: B

#P1
##EASY
###BC

27. ________ many tasks does Spark run on each partition?

A. Any number of task 
B. one 
C. more than one 
D. more than one less than five 

Answer: B

#P1
##EASY
###TF

28. we edit the data of RDD, for example, the case conversion.

A. True 
B. false 

Answer: B

#P1
##EASY
###BC

29. _______  is not a transformation?

A. Flatmap 
B. Map
C. Reduce 
D. Filter 

Answer: C

#P1
##EASY
###BC

30. ______ is not an action?

A. collect ()
B. taken(n)
C. top()
D. map

Answer: D

#P1
##EASY
###TF

31. The data required to compute resides on the single partition.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

32. The data required to compute resides on multiple partitions.

A. True 
B. False 

Answer: B

#P1
##EASY
###TF

33. The data required to compute resides on multiple partitions.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

34. When we want to work with the actual dataset, at that point we use Transformation?

A. True 
B. False 

Answer: B

#P1
##EASY
###BC

35. To overcome by spark RDD to shortcomings Hadoop ?

A. Lazy evaluation 
B. DAG
C. In memory processing 
D. All of the above 

Answer: D

#P1
##EASY
###BC

36. ______ does Spark Engine do?

A. Scheduling 
B. Distributing data across a cluster 
C. Monitoring data across a cluster 
D. All of the above 

Answer: B

#P1
##EASY
###TF

37. Caching is optimizing the technique.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

38. Map transforms an RDD of length N into another RDD of length N.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

39. Map operation developer can define his own custom business logic.

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

40. FlatMap transforms an RDD of length N into another RDD of length M. which of the following is true for N and M.

a. N>M
b. N<M
c. N<=M


A. Either a or B
B. Either b or c 
C. Either a or c 
D. None 

Answer: B

#P1
##EASY
###BC

41. ______ of the following is a transformation?

A. taken(n)
B. top()
C. countByValue()
D. mappartitionWithIndex()

Answer: D

#P1
##EASY
###BC

42. which of the following Action the result is not returned to the driver.

A. collect()
B. top()
C. countByValue()
D. foreach()

Answer: D

#P1
##EASY
###TF

43. The processing of each batch has no dependency on the data of previous batches for stateless transformation.

A. True 
B. False 

Answer: A

#P1
##EASY
###TF

44. Uses data or intermediate results from previous batches and computes the result of the current batch for stateless transformation.

A. True 
B. False 

Answer: B

#P1
##EASY
###BC

45. Windowed operations and updateStateByKey() are two type of Stateless transformation.

A. True 
B. False 

Answer: B

#P1
##EASY
###BC

46. Which of the following organized a data into a named column?

a. RDD
b. DataFrame
c. Dataset


A. Both a and B
B. Both b and C 
C. only a 
D. only b 

Answer: B

#P1
##EASY
###BC

47. _______ provide the object-oriented programming interface?

A. RDD 
B. DataFrame 
C. dataset
D. None of the above 

Answer: C

#P1
##EASY
###BC

48. Transforming into DataFrame one cannot regenerate a domain object.

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

49. Which make use of an encoder for serialization.

A. RDD
B. DataFrame 
C. Dataset 
D. None 

Answer: C

#P1
##EASY
###TF

50. Spark is presently added in all major distribution of Hadoop.

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

51. Does Dataset API support Python?

A. Yes 
B. No 
C. maybe 
D. Sometimes

Answer: B

#P1
##EASY
###BC

52. _________ is slow to perform simple grouping and aggregation operations.

A. RDD 
B. DataFrame 
C. Dataset 
D. All of the above 

Answer: A

#P1
##EASY
###BC

53. ________ is good for low-level transformation and actions.

A. RDD 
B. DataFrame 
C. Dataset 
D. All of the above 

Answer: A

#P1
##EASY
###BC

54. Which technology is good for Stream technology?

A. Apache Spark 
B. Apache Hadoop 
C. Apache Flink 
D. none 

Answer: C

#P1
##EASY
###TF

55. Using SQL we can query data,only from inside a Spark program and not from external tools for sprak execution?

A. True 
B. False 

Answer: B

#P1
##EASY
###TF

56. To simplify working with structured data it provides DataFrame abstraction in Python for spark execution .

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

57. The optimizer helps us to run queries in the same speed as their counter RDD part for Catalyst optimizer.

A. True 
B. False 

Answer: B

#P1
##EASY
###BC

58. The optimizer helps us to run queries little faster than their counter RDD part for Catalyst optimizer.

A. True 
B. False 

Answer: B

#P1
##EASY
###BC

59. The optimizer helps us to run queries much faster than their counter RDD part for Catalyst optimizer.

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

60. _______  are uses of Apache Spark SQL?

A. It executes SQL queries.
B. We can read data from existing Hive installation using SparkSQL.
C. When we run SQL within another programming language we will get the result as Dataset/DataFrame.
D. All of the above 

Answer: D

#P1
##EASY
###TF

61. The help of Spark SQL, we can query structured data as a distributed dataset (RDD).

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

62. Spark SQL, we can create or read a table containing union fields.

A. True 
B. False 

Answer: B

#P1
##EASY
###BC

63. ______  is true for Spark SQL?

A. Hive transactions are not supported by Spark SQL.
B. No support for time-stamp in Avro table.
C. Even if the inserted value exceeds the size limit, no error will occur.
D. All of the above 

Answer: D

#P1
##EASY
###BC

64. _________ is leverage of Spark core fast scheduling capability to perform streaming analytics?

A. Spark Streaming 
B. MLlib 
C. Graphx 
D. RDDs 

Answer: A

#P1
##EASY
###BC

65. Which is a basic abstraction of Spark Streaming?

A. Shared Variable 
B. RDD 
C. Dstream 
D. All the above 

Answer: C

#P1
##EASY
###BC

66. Which cluster manager to do support of Spark?

A. YARN 
B. Standalone cluster manager 
C. Pseudo Cluster manager 
D. ALL of the above 

Answer: D

#P1
##EASY
###BC

67. Which of the following is the reason for Spark being faster than MapReduce while execution time?

A. It supports different programming languages like Python.
B. RDDs
C. DAG execution engine and in-memory computation (RAM based)
D. All of the above 

Answer: C

#P1
##EASY
###TF

68. DAG execution engine and in-memory computation (RAM based) in Spark.

A. True 
B. False 

Answer: A

#P1
##EASY
###BC

69. Fault Tolerance in RDD is achieved using ______?

A. Immutable nature of RDD 
B. DAG 
C. Lazy evaluation 
D. NONE 

Answer: B

#P1
##EASY
###BC

70. ________ is action in Spark RDD?

A. The ways to send result from executors to the driver
B. Takes RDD as input and produces one or more RDD as output.
C. Creates one or many new RDDs
D. All of the above

Answer: A
