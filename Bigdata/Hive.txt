Hive

#P1
##EASY
###TF
1.Hive supports the notion of enclosing characters that may include field delimeters in the enclosing string.

A.True
B.False

Answer:B
Explanation:Hive does not supports the notion of enclosing characters that may include field delimeters in the enclosing string.

#P1
##EASY
###BC
2.Which of the following are features of Hive?

A.Hive is an RDBMS.
B.Hive is a distributed file system.
C.Hive is a resource manager in Hadoop that is used to analyze data stored in HDFS.
D.Hive is a data warehouse system that is used to query and analyze large datasets stored in the HDFS.

Answer:D

#P1
##EASY
###TF
3.State True/False:Hive is based on the notion of reading and writing many times.

A.True
B.False

Answer:B
Explanation:Hive is based on the notion of write once and read many times. RDBMS is based on the notion of reading and writing many times.

#P1
##EASY
###BC
4.Which of the following is true for Static Partitioning in Hive?

A.It is required to pass the values of partitioned columns manually while loading the data into the table.  
B.The values of partitioned columns exist within the table.So, it is not required to pass the values of partitioned columns manually.  
C.The data stored in Static Partitions cannot be changed.
D.The data is stored in Static Partitions based on a formula that Hadoop uses by applying a Hash to the value and dividing it by the number of partitions.

Answer:A

#P1
##EASY
###BC
5.Consider there are 50000 Records in one hive table and you have loaded it in spark -shell for development purposes. What would be the best practice to write code?

A.we can use range
B.we can use limit_record
C.we can use 50000
D.we can use limit function

Answer:D
Explanation:In that case we can use limit function(say 1000 records),cache it and then use it .

#P1
##EASY
###BC
6.SQL Windowing functions are implemented in Hive using which keywords?

A.UNION DISTINCT, RANK
B.OVER, RANK
C.OVER, EXCEPT
D.UNION DISTINCT, RANK

Answer:B

#P1
##EASY
###BC
7.Which Hive query returns the first 1000 values from the table?

A.SELECT…WHERE value = 1000
B.SELECT … LIMIT 1000
C.SELECT TOP 1000 …
D.SELECT MAX 1000…

Answer:B

#P1
##EASY
###TF
8.State True/False:Multiline comments are supported in Hive

A.True
B.False

Answer:B
Explanation:No, as of now multiline comments are not supported in Hive, only single-line comments are supported.

#P1
##EASY
###BC
9.Where is table data stored in Apache Hive by default?

A./user/warehouse
B./user/hives/datawarehouse
C./user/hive/warehouses
D./user/hive/warehouse

Answer:D
Explanation:Hive stores tables files by default at /user/hive/warehouse location on HDFS file system.

#P1
##EASY
###BC
10.Which of the following formula is used by Hadoop to determine which bucket to store the data in?

A.f(x) % n
B.f(x) / n
C.f(x) + n
D.f(x) * n

Answer:A

#P1
##EASY
###BC
11.Which of the folllowing commands cna be used to create a table where the fields are delimited by '%'?

A.create table demo.employee (Id int, Name string , Salary float)    row format delimited    fields terminated by '%' ;
B.create table demo.employee (Id int, Name string , Salary float)    row format delimited    fields terminated by ',' ;
C.create table demo.employee (Id int, Name string , Salary float)    row format terminated    fields delimited by '%' ;
D.create table demo.employee (Id int, Name string , Salary float)    row format terminated    fields delimited by ',' ;

Answer:A

#P1
##EASY
###TF
12.State True/False:It is possible to import or export tables in HBase.

A.True
B.False

Answer:A

#P1
##EASY
###TF
13.If we try to drop an external table, the metadata of the table will be deleted, but the data still exists.

A.True
B.False

Answer:A
Explanation:As the table is external, the data is not present in the Hive directory.Therefore, if we try to drop the table, the metadata of the table will be deleted, but the data still exists.

#P1
##EASY
###BC
14.Which of the following commands can be used to create an external table in Hive?

A.create external table employees (Id int, Name string , Salary float)   row format delimited   fields terminated by ','    location '/user/foo/inputdata';  
B.create external table employees (Id int, Name string , Salary float)   row format delimited   fields terminated by ',';
C.create table employees (Id int, Name string , Salary float)   row format delimited   fields terminated by ','    location '/user/foo/inputdata';  
D.create external table employees (Id int, Name string , Salary float)   row format delimited   fields terminated by ','    hdfs-location '/user/foo/inputdata';  

Answer:A

#P1
##EASY
###TF
15.State True/False:HIVE can perform all CRUD operation with the help of ACID operations.

A.True
B.False

Answer:A

#P1
##EASY
###BC
16.Which of the following commands can be used to load data stored in HDFS into a table in Hive?

A.load data inpath '/home/foouser/inputdata/emp_details' into table employees;  
B.load data '/home/foouser/inputdata/emp_details' into table employees;  
C.load data inpath '/home/foouser/inputdata/emp_details' into external table employees;  
D.load data hdfspath '/home/foouser/inputdata/emp_details' into table employees;  

Answer:A

#P1
##EASY
###BC
17.Which of the following commands will display the partitions of a table?

A.SHOW PARTITIONS <table name>;
B.SHOW PARTITIONS <dbname>;
C.SHOW PARTITIONS;
D.LIST PARTITIONS <table name>;

Answer:A

#P1
##EASY
###TF
18.We can create a hive table with an partition key for a particular column along with the data type.

A.True
B.False

Answer:A
Explanation:The Hive partition table can be created using PARTITIONED key for a particular column along with the data type.

#P1
##EASY
###BC
19.Which is the correct command to display the tables in Hive?

A.hive>SHOW TABLES;
B.hive>DIS TABLES;
C.hive>TABLES;
D.ERROR 

Answer:A

#P1
##EASY
###BC
20.Which is the appropriate syntax using for commands inline?

A.%hive -e 
B.%hive -s  
C.%hive -f  
D.None  

Answer:A

#P1
##EASY
###BC
21.Which of the following commands can be used to load data stored in the local directory into a table in Hive?

A.load data local inpath '/home/foouser/input_data/emp_details' into table employees;  
B.load data inpath '/home/foouser/input_data/emp_details' into table employees;  
C.load data localpath '/home/foouser/input_data/emp_details' into table employees;  
D.load data local inpath '/home/foouser/input_data/emp_details' into external table employees; 

Answer:A

#P1
##EASY
###BC
22.Which is the central repository for storing all the hive metadata?

A.metadata
B.metastore
C.datawarehouse
D.None of the above

Answer:B
Explanation:metastore as a central repository for storing all the Hive metadata information. Hive metadata includes various types of information like structure of tables

#P2
##EASY
###BC
23.What is the full form of HWI?

A.Hive World Internet
B.Hive Web Interface 
C.Hive Wire Internet 
D.Hive World Interface 

Answer:B

#P1
##EASY
###BC
24.TINYINT supports _____ byte signed integer?

A.1
B.2
C.3
D.4
    
Answer:A

#P1
##EASY
###TF
25.State True/False:SmallINT supports 2 byte signed integer.

A.True
B.False

Answer:True

#P1
##EASY
###BC
26.What is the maximum size of data Hive can handle?

A.12GB
B.2TB
C.2GB
D.12GB

Answer:C
Explanation:The maximum size of a string data type supported by Hive is 2 GB. Hive supports the text file format by default, and it also supports the binary format sequence files, ORC files, Avro data files, and Parquet files.

#P1
##EASY
###MA
27.Which of the following are valid AVRO types?

A.Record
B.Arrays
C.Unions
D.JSON

Answer:A,B & C
Explanation:Record,Arrays and unions are the valid AVRO types.

#P1
##EASY
###BC
28.Which of the following is the correct way to define a map type in an AVRO schema? 

A.{"name": "additional", "type": {"type": "map", "values": "string"}}
B.{"name": "additional", "type": ["type": "map", "values": "string"]}
C.{"name": "additional", "type": "map", "values": "string"}
D.{"name": "additional", "type": "map", {"values": "string"}}

Answer:A

#P1
##EASY
###BC
29.In what format is the AVRO schema structure created?

A.JSON
B.CSV
C.XML
D.Binary

Anwer:A
Explanation:An Avro schema is created using JSON format. JSON is short for JavaScript Object Notation, and it is a lightweight, text-based data interchange format.

#P2
##EASY
###BC
30.What is AVRO?

A.Avro is a java compression library. 
B.Avro is a java serialization library.
C.Avro is a java library that create split table files.
D.None of these answers are correct.

Answer:A

#P1
##EASY
###BC
31.Can you run Map - Reduce jobs directly on Avro data?

A.Yes, Avro was specifically designed for data processing via Map-Reduce. 
B.Yes, but additional extensive coding is required.
C.No, Avro was specifically designed for data storage only.
D.Avro specifies metadata that allows easier data access. This data cannot be used as part of map-reduce execution, rather input specification only.

Answer:A

#P1
##EASY
###TF
32.State True/False:Hive is designed for Online transaction processing (OLTP).

A.True
B.False

Answer:False
Explanation:Hive is not designed for Online transaction processing (OLTP).It is designed only for (OLAP).

#P1
##EASY
###BC
33.What is Serializaiton?

A.The process of converting complex objects (array, dicts, lists, class objects, JSON, etc) into byte streams so that they can be stored or transferred to other machines.
B.When the data, once received, is converted in to it's original form.
C.It is a framework library.
D.It is a framework that is used by YARN to process data.

Answer:A

#P1
##EASY
###TF
34.State True/False:In Hive, sub queries are not supported.

A.True
B.False

Answer:A
Explanation:In hive sub queries are not supported.

#P1
##EASY
###BC
35.What happens when the scema does not match the file content?

A.It cannot read the file
B.It reads only the string data type
C.it throws an error and stops reading the file
D.It returns null values for mismatched fields.

Answer:D

#P1
##EASY
###BC
36.Choose the correct statements about the Hive.

A.Hive supports sub query.
B.Hive supports overwriting
C.Hive supports deletes
D.All of the above

Answer:B
Explanation:Hive supports only the overwriting but i will not supports deletes.

#P2
##EASY
###BC
37.Which type of tables used to Creating  a table As well as loading data from a select clause.

A.only managed tables
B.only external tables
C.Both types of tables
D.Only tables without partitions

Answer:A

#P2
##EASY
###TF
38.Hive is a distributed data warehouse.

A.True
B.False

Answer:A

#P1
##EASY
###TF
39.State True/False:Hive supports updates and deletes

A.True
B.False

Answer:B
Explanation:Hive does not supports updates and deletes.

#P1
##EASY
###BC
40.Which query is used to select all columns starting with the word 'Bought' form the table GROSS the query is ?

A.select '$Bought*'  from GROSS 
B.select 'Bought*' from GROSS
C.select 'Bought.*' from GROSS
D.select  'Bought[*]' from GROSS
    
Answer:C

#P1
##EASY
###BC
41.What will happen when index is dropped?

A.The underlying table is also dropped
B.The underlying table is not dropped
C.The directory containing the index is delted
D.Error is thrown by hive

Answer:D

#P1
##EASY
###TF
42.State True/False:Hive needs a relational database like oracle to perform query operations and store data.

A.True
B.False

Answer:B
Explanation:Hive needs a relational database like oracle to perform query operations and store data is incorrect with the respect to hive.

#P2
##EASY
###BC
43.Consider we have a Hive table is created as an external table,If we drop the table will be the data is accessible?

A.Not accessible 
B.We can't able to create external table
C.It is accessible
D.None of the above

Answer:C
Explanation:The data will be accessible even if the table gets dropped. We can get the data from the table’s HDFS location.

44.

  


















